{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "##http://data8.org/datascience/tables.html\n",
    "from datascience import *\n",
    "import pandas as pd ##Importing panda Library\n",
    "import numpy as np\n",
    "import time\n",
    "import seaborn as sns \n",
    "import matplotlib.pyplot as plt \n",
    "from sklearn.model_selection import train_test_split  #data_split\n",
    "from sklearn.svm import SVC  #SVM\n",
    "from sklearn.metrics import classification_report, confusion_matrix  #model eval\n",
    "from sklearn.metrics import mean_squared_error\n",
    "from sklearn import preprocessing\n",
    "from math import sqrt\n",
    "from sklearn.decomposition import PCA\n",
    "import random\n",
    "\n",
    "##Random Forest\n",
    "from sklearn.model_selection import train_test_split #training and testing split\n",
    "from sklearn.preprocessing import StandardScaler  #feature scaling\n",
    "from sklearn.ensemble import RandomForestRegressor  #random forest\n",
    "from sklearn import metrics  #model evaluation\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "##XGboost\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.metrics import accuracy_score\n",
    "\n",
    "\n",
    "%matplotlib inline\n",
    "harmony = pd.read_csv(\"Harmony_data.csv\") #Reading the CSV file (My Data Frame)\n",
    "test = pd.read_csv(\"production_data_test.csv\") #Reading the CSV file (My Data Frame)\n",
    "train = pd.read_csv(\"production_data_train.csv\") #Reading the CSV file (My Data Frame)\n",
    "ihs = pd.read_csv(\"IHS_data.csv\") #Reading the CSV file (My Data Frame)\n",
    "api = pd.read_csv(\"test_APIs.csv\", header = None) #Reading the CSV file (My Data Frame) \n",
    "api.columns = [\"API\"] \n",
    "test = pd.merge(left= api,right=test, left_on= 'API', right_on='API')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "##DFS\n",
    "##Remove Duplicates\n",
    "train_df = train.drop_duplicates()\n",
    "train_df = train_df.sort_values(by = ['API','Year', 'Month']) \n",
    "dfs = [x.reset_index(drop = True) for _,x in train_df.groupby('API')] ##Divide the data into list of dataframes\n",
    "count = 0\n",
    "for d in range(0,len(dfs)):\n",
    "    maxx = dfs[d][\"Liquid\"].idxmax()\n",
    "    dfs[d] = dfs[d].iloc[maxx:,:]\n",
    "    indexx = np.arange(1,len(dfs[d]) + 1,1)\n",
    "    dfs[d]['Month_Index'] = indexx.tolist()\n",
    "train_df_data = pd.concat(dfs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>API</th>\n",
       "      <th>Liquid</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <td>0</td>\n",
       "      <td>5001097720000</td>\n",
       "      <td>65412</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>1</td>\n",
       "      <td>5001097780100</td>\n",
       "      <td>84043</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>2</td>\n",
       "      <td>5001097800000</td>\n",
       "      <td>13471</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>3</td>\n",
       "      <td>5001097820000</td>\n",
       "      <td>12992</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>4</td>\n",
       "      <td>5001097830000</td>\n",
       "      <td>15195</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7826</td>\n",
       "      <td>49021222940000</td>\n",
       "      <td>227454</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7827</td>\n",
       "      <td>49021222950000</td>\n",
       "      <td>211789</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7828</td>\n",
       "      <td>49021223030000</td>\n",
       "      <td>230485</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7829</td>\n",
       "      <td>49021226570000</td>\n",
       "      <td>26615</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <td>7830</td>\n",
       "      <td>49021226580100</td>\n",
       "      <td>31585</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>7831 rows Ã— 2 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                 API  Liquid\n",
       "0      5001097720000   65412\n",
       "1      5001097780100   84043\n",
       "2      5001097800000   13471\n",
       "3      5001097820000   12992\n",
       "4      5001097830000   15195\n",
       "...              ...     ...\n",
       "7826  49021222940000  227454\n",
       "7827  49021222950000  211789\n",
       "7828  49021223030000  230485\n",
       "7829  49021226570000   26615\n",
       "7830  49021226580100   31585\n",
       "\n",
       "[7831 rows x 2 columns]"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Apis_36 = train_df_data[train_df_data.Month_Index == 36]\n",
    "new_df = pd.merge(left= train_df_data , right=Apis_36['API'], left_on= 'API', right_on='API')\n",
    "my_df_sum = new_df.groupby('API').apply(lambda x: x.iloc[0:36])\n",
    "my_df_sum = my_df_sum.rename(columns = {\"API\": \"API2\"})\n",
    "my_df_sum = my_df_sum.groupby('API')['Liquid'].sum().reset_index()\n",
    "my_df_sum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "merged = pd.merge(my_df_sum, ihs, on='API')\n",
    "new_df = pd.merge(merged, harmony, on='API')\n",
    "train_final = new_df[['API', 'Liquid', 'BasinName', 'StateName',\n",
    "                   'LatWGS84', 'LonWGS84','LATERAL_LENGTH_BLEND',\n",
    "                   'PROP_PER_FOOT', 'WATER_PER_FOOT',\n",
    "                       'GOR_30']]\n",
    "#, 'GOR_60', 'GOR_90'  'BottomHoleLatitude', 'BottomHoleLongitude',\n",
    "\n",
    "train_final = train_final.fillna(train_final[['LatWGS84', 'LonWGS84','LATERAL_LENGTH_BLEND',\n",
    "       'GOR_30', 'PROP_PER_FOOT', 'WATER_PER_FOOT']].median())\n",
    "\n",
    "train_df_final = pd.get_dummies(train_final, columns=[\"BasinName\", \"StateName\"], \n",
    "                    prefix=[\"basin\", \"state\"], drop_first = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.stats import chi2_contingency\n",
    "csq=chi2_contingency(pd.crosstab(train_final['BasinName'], train_final['Liquid']))\n",
    "print(\"P-value: \",csq[1])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Trial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#training = train_df_final[~my_df_final.API.isin(api.API)]\n",
    "train_x = train_df_final[train_df_final.columns.difference(['API', 'Liquid'])]\n",
    "#pca = PCA(n_components=5)\n",
    "#principalComponents = pca.fit_transform(train_x)\n",
    "#principalDf = pd.DataFrame(data = principalComponents\n",
    "            # , columns = ['principal component 1', 'principal component 2', \n",
    "                        #  'principal component 3','principal component 4', 'principal component 5'])\n",
    "train_y = train_df_final.loc[:,train_df_final.columns == 'Liquid']\n",
    "random.seed(9001)\n",
    "x_train, x_test, y_train,y_test=train_test_split(train_x,train_y,test_size=0.2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "46974.55840139909"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Random Forest\n",
    "x_train2 = preprocessing.normalize(x_train)\n",
    "x_test2 = preprocessing.normalize(x_test)\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(x_train, y_train)\n",
    "y_pred = regressor.predict(x_test)\n",
    "rms = sqrt(mean_squared_error(y_test, y_pred))\n",
    "rms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Training Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:5: DataConversionWarning: A column-vector y was passed when a 1d array was expected. Please change the shape of y to (n_samples,), for example using ravel().\n",
      "  \"\"\"\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "RandomForestRegressor(bootstrap=True, criterion='mse', max_depth=None,\n",
       "                      max_features='auto', max_leaf_nodes=None,\n",
       "                      min_impurity_decrease=0.0, min_impurity_split=None,\n",
       "                      min_samples_leaf=1, min_samples_split=2,\n",
       "                      min_weight_fraction_leaf=0.0, n_estimators=200,\n",
       "                      n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
       "                      warm_start=False)"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_x = train_df_final[train_df_final.columns.difference(['API', 'Liquid'])]\n",
    "train_y = train_df_final.loc[:, train_df_final.columns == 'Liquid']\n",
    "train_x = preprocessing.normalize(train_x)\n",
    "regressor = RandomForestRegressor(n_estimators=200, random_state=0)\n",
    "regressor.fit(train_x, train_y)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Test Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "new_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([202620.615, 169515.89 , 169500.705, ..., 101542.91 , 170008.455,\n",
       "        55756.46 ])"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "merged = pd.merge(api, ihs, on='API')\n",
    "new_df = pd.merge(merged, harmony, on='API')\n",
    "test_final = new_df[['API', 'BasinName',\n",
    "                   'LatWGS84', 'LonWGS84','LATERAL_LENGTH_BLEND',\"StateName\",\n",
    "                   'PROP_PER_FOOT', 'WATER_PER_FOOT',\n",
    "                       'GOR_30']]\n",
    "#, 'GOR_60', 'GOR_90'  'BottomHoleLatitude', 'BottomHoleLongitude',\n",
    "\n",
    "test_final = test_final.fillna(test_final[['LatWGS84', 'LonWGS84','LATERAL_LENGTH_BLEND',\n",
    "       'GOR_30', 'PROP_PER_FOOT', 'WATER_PER_FOOT']].median())\n",
    "\n",
    "test_df_final = pd.get_dummies(test_final, columns=[\"BasinName\", \"StateName\"], \n",
    "                    prefix=[\"basin\", \"state\"], drop_first = True)\n",
    "\n",
    "test_x = test_df_final[test_df_final.columns.difference(['API'])]\n",
    "#test_y = test_df_final.loc[:, test_df_final.columns == 'Liquid']\n",
    "test_x = preprocessing.normalize(test_x)\n",
    "y_pred = regressor.predict(test_x)\n",
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Fun \n",
    "test_df = test.drop_duplicates()\n",
    "test_df = test_df.sort_values(by = ['API','Year', 'Month']) \n",
    "\n",
    "dfs = [x.reset_index(drop = True) for _,x in test_df.groupby('API')] ##Divide the data into list of dataframes\n",
    "count = 0\n",
    "for d in range(0,len(dfs)):\n",
    "    maxx = dfs[d][\"Liquid\"].idxmax()\n",
    "    dfs[d] = dfs[d].iloc[maxx:,:]\n",
    "    indexx = np.arange(1,len(dfs[d]) + 1,1)\n",
    "    dfs[d]['Month_Index'] = indexx.tolist()\n",
    "test_df_data = pd.concat(dfs)\n",
    "\n",
    "Apis_36 = test_df_data[test_df_data.Month_Index == 36]\n",
    "new_df = pd.merge(left= test_df_data , right=Apis_36['API'], left_on= 'API', right_on='API')\n",
    "test_df_data = new_df.groupby('API').apply(lambda x: x.iloc[0:36])\n",
    "my_df_sum = test_df_data.rename(columns = {\"API\": \"API2\"})\n",
    "my_df_sum = my_df_sum.groupby('API')['Liquid'].sum().reset_index()\n",
    "ready = pd.merge(left= my_df_sum , right=api['API'], left_on= 'API', right_on='API')\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72729.61774531697"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "##Compare the APIS that reached 36 in test with our predictions\n",
    "api[\"Predicted\"] = y_pred\n",
    "compares = pd.merge(api, ready, how=\"left\", on='API').dropna() \n",
    "rms = sqrt(mean_squared_error(compares.Predicted, compares.Liquid))\n",
    "rms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "##Save\n",
    "api[\"Predicted\"] = y_pred\n",
    "api.columns = [\"Id\",\"Predicted\"] \n",
    "api.to_csv('PREDICTIONS.csv', index = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.model_selection import GridSearchCV\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "\n",
    "rfc=RandomForestClassifier(random_state=42)\n",
    "param_grid = { \n",
    "    'n_estimators': [200, 500],\n",
    "    'max_features': ['auto', 'sqrt', 'log2'],\n",
    "    'max_depth' : [4,5,6,7,8],\n",
    "    'criterion' :['gini', 'entropy']\n",
    "}\n",
    "CV_rfc = GridSearchCV(estimator=rfc, param_grid=param_grid, cv= 3)\n",
    "CV_rfc.fit(train_x, train_y)\n",
    "CV_rfc.best_params_"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
